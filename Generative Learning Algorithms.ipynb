{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成学习算法\n",
    "\n",
    "以线性回归、逻辑回归为代表的广义线性模型，都是在针对 $p(y|x;\\theta)$，也就是给定 $x$ 时 $y$ 的条件概率分布进行建模。\n",
    "\n",
    "以分类问题为例，给定一个训练集，逻辑回归，试图寻找一条直线——也就是决策边界——来区分正类和反类。模型建立后，对于一个新的测试样本，给定其特征，我们判定这个样本落在决策边界的哪一侧，然后据此做出预测。\n",
    "\n",
    "直接学习 $p(y|x)$ 的算法，或者说直接将输入空间 $\\chi$ 映射到标签 $\\{0, 1\\}$的算法，称为**判别学习算法 Discriminative Learning Algorithm**。与此相反，针对 $p(x|y)$ 建模的算法，称为**生成学习算法 Generative Learning Algorithm**。\n",
    "\n",
    "还是以分类问题为例，生成学习算法通过对训练集的学习，给定一个分类 $y \\in \\{0, 1\\}$，我们的模型试图描述这个分类对应的特征的分布。\n",
    "\n",
    "通过对 $p(y)$ （称为**先验概率 class prior**）和 $p(x|y)$ 建模，我们之后通过贝叶斯法则来计算给定 $x$ 时 $y$ 的后验分布：\n",
    "$$ p(y|x) = \\frac{p(x|y)p(y)}{p(x)} $$\n",
    "\n",
    "其中，分母 $p(x) = p(x|y=1)p(y=1)+p(x|y=0)p(y=0)$。而实际上，在预测时，我们并不需要计算 $p(x)$，因为\n",
    "$$\n",
    "\\begin{split}\n",
    "arg \\max_yp(y|x) &= arg \\max_y\\frac{p(x|y)p(y)}{p(x)} \\\\\n",
    "&= arg \\max_yp(x|y)p(y)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "本节包括一下内容：\n",
    "1. 高斯判别分析\n",
    "2. 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
