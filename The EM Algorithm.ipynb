{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM算法 The EM Algorithm \n",
    "\n",
    "之前在讲高斯混合模型时，用到了EM算法。而EM算法实际是更加广泛的概念，专门用来解决包含隐含随机变量的估计问题。\n",
    "\n",
    "本节包含以下内容：\n",
    "1. Jensen不等式 Jensen's inequality\n",
    "2. EM算法 The EM Algorithm\n",
    "3. 回顾高斯混合模型 Mixture of Gaussians revisited\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Jensen不等式 Jensen's Inequality\n",
    "\n",
    "令 $f$ 为定义域在实数集上的函数。如果 $\\forall x \\in \\mathbb{R}, f^{\\prime\\prime}(x) \\geq 0$，则称 $f$ 是凸函数。当 $f$ 的变量是向量时，则条件推广为 $f$ 的海森矩阵 $H$ 是正定矩阵（$H \\geq 0$）。如果 $\\forall x \\in \\mathbb{R}, f^{\\prime\\prime}(x) > 0$，则称 $f$ 是严格凸函数（向量函数的情况，对应的条件为 $H$ 是严格正定矩阵，写作 $H>0$）。Jensen不等式的表述如下：\n",
    "\n",
    "**定理**：如果 $f$ 是凸函数，令 $X$ 表示某个随机变量，那么 $E[f(X)] \\geq f(EX)$\n",
    "\n",
    "另外，如果 $f$ 是严格凸函数，那么当且仅当以 $1$ 的概率 $X=E[X]$ 时（也即 $X$ 是常数），有 $E[f(X)]=f(EX)$ 。\n",
    "\n",
    "为了方便记忆，可以想象 $f(x) = x^2$，而 $X$ 是一个服从参数 $0.5$ 的伯努利分布随机变量，取值范围为 $a, b$。那么，$f(EX)=f(\\frac{a+b}{2})=\\frac{(a+b)^2}{4}$，而 $E[f(x)]=\\frac{f(a)+f(b)}{2}=\\frac{a^2+b^2}{2}$，显然 $E[f(X)] \\geq f(EX)$。\n",
    "\n",
    "**备注**：当且仅当 $-f$ 是（严格）凸函数时，$f$ 是（严格）凹函数（即 $f^{\\prime\\prime}\\leq0$ 或 $H \\leq 0$）。对于凹函数来说，Jensen不等式的方向改变，$E[f(X)] \\leq f(EX)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
